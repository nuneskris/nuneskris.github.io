---
title: "Data Fabric in 2 mins"
collection: publications
permalink: /publication/data-frabic-overview
excerpt: '
What? Enterprise wide consisted data management design.
Why? Reduce the time to deliver data integration and interoperability
How? Through metadata.'
date: 2024-02-17
---

What?, Why?,  How?
======
Enterprise wide consisted data management design.
------
Reduce the time to deliver data integration and interoperability
------
Through metadata.
------
According to the Gartner who has been pushing this for a while.
> *'A data fabric maps data residing in disparate applications (within the underlying data stores, regardless of the original deployment designs and locations) and makes them ready for business exploration.'*

I believe, at the core Data Fabric, it is striving to ***reduce time*** to integrate data. Data warehouses integrate data from ***various*** sources, providing a unified view for analysis. Inmon, Kimbal, DataLake, Lakehouse, Logical warehouse tried to achive this. This would ne the 



use a consistent metadata standards to realize  
        - unified data
        - semantic data.

1. Describe: What the data is.
    * Unified Data Model: An inclusive data model which 
        * consolidates commonalities 
        * accommodates exclusivities.
    * Data Catalog
2. Organize: 
    * Unified Data: is when many fragmented data sources are merged into one logical data set based on the unified data model.
    * Resource URI & URI Endpoints (URL)
3. Share:  
    * Uniform Interface: Data across the enterprise needs to be accessed via a uniform interface.
4. Integrate:  
    * Semantic Model with self described Data Integration: 
        * Hypermedia with linked relationships, RDF, Graphql
